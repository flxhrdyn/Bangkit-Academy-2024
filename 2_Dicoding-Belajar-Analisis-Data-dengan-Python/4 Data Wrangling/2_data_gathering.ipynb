{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering\n",
    "Sebelum mulai, perlu Anda ketahui bahwa proses pengumpulan data merupakan salah satu tahapan paling menantang dalam proyek analisis data. Bergantung pada proyek analisis data yang dikerjakan, data yang Anda butuhkan mungkin terdapat dalam berbagai sumber dan memiliki format yang berbeda-beda. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Berbagai Sumber Data\n",
    "Salah satu skill yang harus dimiliki oleh seorang praktisi data ialah mengetahui sumber data yang tepat untuk mengumpulkan data yang dibutuhkan. Oleh karena itu, sangat penting bagi kita untuk mengetahui berbagai sumber data yang umum digunakan. \n",
    "\n",
    "Nah, berikut merupakan beberapa sumber data yang bersifat publik dan sering digunakan oleh para praktisi data.\n",
    "\n",
    "- Kaggle\n",
    "\n",
    "    <img src=\"https://dicoding-web-img.sgp1.cdn.digitaloceanspaces.com/original/academy/dos:eb26e1521788cc7bba31cac1b1d1d58b20230220134340.jpeg\" width=\"300\">\n",
    "\n",
    "    Jika stack overflow merupakan platform favorit bagi para programmer ketika menemukan eror, kaggle merupakan platform andalan bagi praktisi data untuk mencari dataset. Selain menyediakan dataset, kaggle juga menyediakan berbagai kompetisi dan challenge terkait data science dan machine learning. Kaggle juga memungkinkan para praktisi data dan machine learning saling berbagi kode dan pengetahuan terkait data serta machine learning. Untuk mulai menggunakan platform ini, Anda perlu membuat akun terlebih dahulu melalui tautan berikut: kaggle. https://www.kaggle.com/\n",
    "\n",
    "- UCI Machine Learning Repository\n",
    "\n",
    "    <img src=\"https://dicoding-web-img.sgp1.cdn.digitaloceanspaces.com/original/academy/dos:e4af6b9f51ec90efc51f9cd468cddeb520230220134339.jpeg\" width=\"300\">\n",
    "\n",
    "    UCI Machine Learning Repository merupakan sebuah repositori yang menampung berbagai dataset yang bersifat publik. Seluruh dataset tersebut umumnya digunakan untuk kebutuhan akademik maupun bahan latihan bagi calon praktisi data dan machine learning pemula. Anda dapat mengakses repositori ini melalui tautan berikut: UCI Machine Learning Repository https://archive.ics.uci.edu/\n",
    "\n",
    "- Google Dataset Search\n",
    "\n",
    "    Google Dataset Search merupakan sebuah search engine yang disediakan oleh Google. Ia dibuat untuk mempermudah para praktisi data dan juga researcher dalam mencari dataset yang bersifat publik. Cara penggunaannya mirip seperti ketika kita menggunakan Google Search. Anda dapat mengaksesnya melalui tautan berikut: Google Dataset Search. https://datasetsearch.research.google.com/\n",
    "\n",
    "- Satu Data Indonesia\n",
    "\n",
    "    <img src=\"https://dicoding-web-img.sgp1.cdn.digitaloceanspaces.com/original/academy/dos:492213fb9c3a2af0c642f4e3034e221020230220134340.jpeg\" width=\"300\">\n",
    "    \n",
    "    Tahukah Anda bahwa pemerintah Indonesia sebetulnya telah menyediakan sebuah platform bernama Satu Data Indonesia atau sering disingkat SDI. Platform ini dibuat sebagai bentuk kebijakan tata kelola data pemerintah yang bertujuan untuk menciptakan data berkualitas dan mudah diakses. Platform ini dikelola oleh Sekretariat Satu Data Indonesia tingkat Pusat yang berada di naungan Kementerian Perencanaan Pembangunan Nasional/Bappenas. Untuk mengakses platform ini, silakan mengunjungi tautan berikut: Satu Data Indonesia. https://data.go.id/home\n",
    "\n",
    "Selain menggunakan berbagai sumber dataset publik tersebut, para praktisi data juga seringkali menggunakan data internal yang bersifat privat. Data seperti ini umumnya disimpan dalam sebuah sistem pengolahan database yang hanya bisa diakses dan digunakan untuk kepentingan internal sebuah organisasi. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Membaca Berbagai Tipe Data Menggunakan Pandas\n",
    "Pada pembahasan sebelumnya kita telah mengenal berbagai sumber data yang umum digunakan oleh praktisi data. Nah, sekarang kita mulai pembahasan tentang cara membaca data menggunakan library pandas.\n",
    "\n",
    "Seperti yang telah kita bahas sebelumnya, pandas merupakan sebuah library Python yang spesifik digunakan untuk memanipulasi dan menganalisis data. Dalam mendukung hal tersebut, pandas menyediakan beberapa function yang dapat digunakan untuk membaca atau mengakses data menjadi sebuah DataFrame.\n",
    "\n",
    "- Format berkas CSV\n",
    "\n",
    "    Berkas CSV (Comma Separated Values) merupakan format berkas data tabel yang paling sering digunakan dan telah menjadi standar dalam industri. Ia menggunakan koma (,) sebagai pemisah (sering disebut sebagai delimiter) antar nilai dalam satu baris.\n",
    "\n",
    "    Pandas menyediakan sebuah function __read_csv()__ untuk membaca berkas CSV. Berikut merupakan contoh penggunaannya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "df = pd.read_csv(\"data.csv\", delimiter=\",\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format berkas XLSX atau XLS\n",
    "\n",
    "    Berkas XLSX atau XLS merupakan format berkas spreadsheet yang dibuat menggunakan aplikasi Microsoft Excel. \n",
    "    \n",
    "    Pandas juga menyediakan function __read_excel()__ untuk membaca berkas data dengan format XLSX atau XLS. \n",
    "    \n",
    "    Berikut merupakan contoh kodenya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "df = pd.read_excel(\"data.xlsx\", sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format berkas JSON\n",
    "\n",
    "    Berkas JSON (JavaScript Object Notation) merupakan format berkas data lain yang paling sering digunakan di industri. Ia sering digunakan karena berukuran kecil, mudah dibaca dan ditulis oleh manusia, serta mudah diproses oleh mesin. JSON memiliki struktur data yang mirip seperti data structure dictionary dalam Python yang terdiri dari pasangan keys dan values.\n",
    "\n",
    "    Sebagai library pengolahan data yang andal, pandas juga menyediakan function __read_json()__ untuk membaca berkas data berformat JSON. Berikut merupakan contoh penggunaan function tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "df = pd.read_json(\"data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format berkas HTML\n",
    "\n",
    "    HTML atau dikenal juga sebagai HyperText Markup Language merupakan sebuah markup language standar yang digunakan untuk merancang tampilan sebuah   dokumen/halaman di web browser. Untuk membaca berkas ini, pandas menyediakan function read_html(). Ia akan menerima inputan berupa HTML string, HTML file, atau URL dan akan mengurai tabel HTML ke dalam bentuk list. List ini berisi kumpulan DataFrame yang diurai dari tabel HTML tersebut. Berikut merupakan contoh kode penggunaan function tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "url = \"https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list\"\n",
    "df = pd.read_html(url)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Format berkas XML\n",
    "\n",
    "    Format data selanjutnya yang akan kita bahas ialah XML. Ia merupakan singkatan dari Extensible Markup Language yang sering digunakan untuk merepresentasikan berbagai struktur informasi, seperti dokumen, data, konfigurasi, dll.\n",
    "\n",
    "    Pandas menyediakan function read_xml()untuk membaca format data ini. Berikut merupakan contoh kode penggunaannya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "df = pd.read_xml(\"https://www.w3schools.com/xml/books.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Akses data dari SQL database\n",
    "    Selain membaca data dari berbagai format, library pandas juga memungkinkan kita untuk mengakses data langsung dari sebuah database, seperti PostgreSQL, MySQL, dll. Tentunya untuk mengakses database tersebut kita membutuhkan library pendukung yaitu SQLAlchemy.\n",
    "\n",
    "    Untuk berinteraksi dengan database, pandas menyediakan tiga function seperti berikut.\n",
    "    - read_sql_table()\n",
    "    \n",
    "        untuk membaca SQL database table dan mempresentasikannya ke dalam bentuk pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy as sqla\n",
    " \n",
    "db = sqla.create_engine(\"sqlite:///mydata.sqlite\")\n",
    " \n",
    "pd.read_sql_table(\"table_name\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- read_sql_query()\n",
    "\n",
    "    untuk membaca SQL query dan mempresentasikannya ke dalam bentuk pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy as sqla\n",
    " \n",
    "db = sqla.create_engine(\"sqlite:///mydata.sqlite\")\n",
    " \n",
    "pd.read_sql_query(\"SELECT * FROM table_name\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- read_sql()\n",
    "\n",
    "    untuk membaca SQL query atau table dan mempresentasikannya ke dalam bentuk pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy as sqla\n",
    " \n",
    "db = sqla.create_engine(\"sqlite:///mydata.sqlite\")\n",
    " \n",
    "pd.read_sql(\"SELECT * FROM table_name\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Menggabungkan Beberapa Data Menjadi Satu DataFrame\n",
    "Salah satu teknik penggabungan data yang paling sering digunakan ialah merge atau join. Bagi Anda yang familier dengan relational database tentunya sudah tidak asing lagi dengan istilah tersebut. Ia merupakan teknik untuk menggabungkan dua tabel data menggunakan primary key (PK) dan foreign key (FK).  \n",
    "\n",
    "Primary key merupakan sebuah kolom dengan nilai unik yang merepresentasikan suatu data dalam sebuah tabel. Di lain sisi, foreign key merupakan kolom yang berisi primary key dari tabel lain. Ia digunakan untuk mereferensikan data dari tabel lain hingga terbentuk sebuah relationship antar tabel. Inilah yang menjadi kunci dalam relational database\n",
    "\n",
    "Berdasarkan cara penggabungannya, proses merge atau join dapat dibagi menjadi empat jenis yaitu seperti berikut. \n",
    "- Inner\n",
    "\n",
    "    Inner join merupakan proses join yang hanya mengambil nilai yang bersesuaian di kedua tabel.\n",
    "\n",
    "- Left\n",
    "\n",
    "    Left join merupakan proses join yang akan mengambil semua nilai dari tabel kiri beserta nilai yang bersesuaian dari tabel kanan.\n",
    "\n",
    "- Right\n",
    "\n",
    "    Right join merupakan proses join yang akan mengambil semua nilai dari tabel kanan beserta nilai yang bersesuaian dari tabel kiri. Ia merupakan kebalikan dari left join.\n",
    "\n",
    "- Outer \n",
    "\n",
    "    Outer join atau sering juga disebut full outer join merupakan proses join yang akan mengambil semua nilai dari kedua tabel. Ia merupakan gabungan dari left dan right join.\n",
    "\n",
    "Sebagai tool andalan dalam pengolahan dan analisis data, pandas menyediakan sebuah function bernama merge(). Ia dapat digunakan untuk menggabungkan dua buah DataFrame. Berikut merupakan contoh kode penggunaannya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "product_df = pd.read_csv(\"product.csv\")\n",
    "orders_df = pd.read_csv(\"orders.csv\")\n",
    " \n",
    "new_order_df = pd.merge(\n",
    "    left=product_df,\n",
    "    right=orders_df,\n",
    "    how=\"inner\",\n",
    "    left_on=\"product_id\",\n",
    "    right_on=\"product_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode di atas akan menghasilkan sebuah DataFrame baru yang hanya mengambil nilai yang bersesuaian dari kedua DataFrame (product_df dan orders_df) tersebut. Proses ini dilakukan dengan menyesuaikan nilai pada kolom product_id yang berperan sebagai primary key dari product_df dan foreign key dari orders_df.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
